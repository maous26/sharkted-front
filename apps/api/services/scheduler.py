"""
Scheduler service - Gestion des jobs de scraping planifi√©s
"""

import asyncio
from datetime import datetime
from typing import Optional
from loguru import logger

from config import settings

# Global scheduler state
_scheduler_task: Optional[asyncio.Task] = None
_scheduler_running: bool = False


async def scraping_job():
    """Job de scraping ex√©cut√© √† intervalles r√©guliers"""
    from database import async_session
    from services.scraping_orchestrator import ScrapingOrchestrator

    logger.info("üîÑ D√©marrage du job de scraping planifi√©...")

    try:
        async with async_session() as db:
            orchestrator = ScrapingOrchestrator(db)
            results = await orchestrator.run_all_scrapers(send_alerts=True)

            logger.info(
                f"‚úÖ Scraping termin√©: {results['total_new_deals']} nouveaux deals, "
                f"{results['total_scored']} scor√©s, {results['alerts_sent']} alertes envoy√©es"
            )

            await db.commit()

    except Exception as e:
        logger.error(f"‚ùå Erreur lors du scraping planifi√©: {e}")


async def scheduler_loop():
    """Boucle principale du scheduler"""
    global _scheduler_running

    interval_minutes = settings.SCRAPE_INTERVAL_MINUTES
    interval_seconds = interval_minutes * 60

    logger.info(f"‚è∞ Scheduler d√©marr√© - Intervalle: {interval_minutes} minutes")

    while _scheduler_running:
        try:
            # Ex√©cuter le job de scraping
            await scraping_job()

            # Attendre l'intervalle suivant
            logger.info(f"üí§ Prochain scraping dans {interval_minutes} minutes...")
            await asyncio.sleep(interval_seconds)

        except asyncio.CancelledError:
            logger.info("üõë Scheduler annul√©")
            break
        except Exception as e:
            logger.error(f"‚ùå Erreur dans la boucle du scheduler: {e}")
            # Attendre un peu avant de r√©essayer en cas d'erreur
            await asyncio.sleep(60)


async def start_scheduler():
    """D√©marre le scheduler de scraping en arri√®re-plan"""
    global _scheduler_task, _scheduler_running

    if _scheduler_task is not None and not _scheduler_task.done():
        logger.warning("‚ö†Ô∏è Le scheduler est d√©j√† en cours d'ex√©cution")
        return

    _scheduler_running = True
    _scheduler_task = asyncio.create_task(scheduler_loop())
    logger.info("üöÄ Scheduler de scraping d√©marr√©")


async def stop_scheduler():
    """Arr√™te le scheduler de scraping"""
    global _scheduler_task, _scheduler_running

    _scheduler_running = False

    if _scheduler_task is not None:
        _scheduler_task.cancel()
        try:
            await _scheduler_task
        except asyncio.CancelledError:
            pass
        _scheduler_task = None

    logger.info("üõë Scheduler de scraping arr√™t√©")


def is_scheduler_running() -> bool:
    """V√©rifie si le scheduler est en cours d'ex√©cution"""
    return _scheduler_running and _scheduler_task is not None and not _scheduler_task.done()
